# docker-compose.yaml
# --------------------
# Orchestrates multi-container setup for CoSMIC Coaching Writer.
# Provides API service plus optional supporting services.

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    entrypoint: ["/bin/sh", "/ollama-entrypoint.sh"]
    healthcheck:
      test: ["CMD-SHELL", "ollama list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 5s
    volumes:
      - ollama:/root/.ollama
      - ./scripts/ollama-entrypoint.sh:/ollama-entrypoint.sh:ro
    restart: unless-stopped
    networks:
      - cosmic_net
    

  coaching-writer:
    build:
      context: .
      dockerfile: Dockerfile
    image: cosmic-coaching-writer:latest
    container_name: coaching-writer
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - LLM_NAME=ollama:gemma2:2b
      - VECTOR_DB_PATH=database/vector_db
      - EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
      - RETRIEVE_TOPK=5
      - RETRIEVE_SCORE_THRESHOLD=0.7
      - VECTOR_DB_UPDATE_THRESHOLD=0.98
      - MAX_NEW_TOKENS=512
      - COACH_STYLE=supportive, concise, academically rigorous
    depends_on:
      ollama:
        condition: service_healthy
    ports:
      - "8001:8001"
    volumes:
      - ./config.yaml:/app/config.yaml:ro
      - ./vector_db:/app/database/vector_db
      - open-webui:/app/backend/data
      - ./academic-texts:/app/academic-texts
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/docs"]
      interval: 15s
      timeout: 10s
      retries: 10
    networks:
      - cosmic_net

  open-webui:
    # build:
    #   context: ../OpenWebUI-CoSMIC
    #   dockerfile: Dockerfile
    # image: opensicbr/openwebui-cosmic:standalone
    image: opensicbr/cosmic_openwebui:latest
    container_name: openwebui
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OPENSI_COSMIC_API_BASE_URL=http://coaching-writer:8001
      # - OLLAMA_BASE_URLS=http://coaching-writer:8001
      - ENABLE_OLLAMA_API=true
      - ENABLE_OPENAI_API=true
      - ENABLE_OAUTH_SIGNUP=false
      - WEBUI_SECRET_KEY=dev-secret

      # --- Force your custom provider + default model ---
      - OPENAI_API_BASE_URL=http://pipelines:9099
      - OPENAI_API_KEY=0p3n-w3bu!
      - DEFAULT_MODELS=CoSMIC-CoachingWriter

      - ENABLE_PIPELINES=true
      - PIPELINES_URL=http://pipelines:9099
    volumes:
      # - ../OpenWebUI-CoSMIC:/app/src:ro
      - ./config.yaml:/app/src/shared/config.yaml:ro
      - ./vector_db:/app/database/vector_db
      - open-webui:/app/backend/data
    depends_on:
      coaching-writer:
        condition: service_started
    ports:
      - "8080:8080"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 15s
      timeout: 10s
      retries: 10
    networks:
      - cosmic_net

  # nginx:
  #   image: nginx:latest
  #   container_name: nginx
  #   ports:
  #     - "3000:80"    # user connects on localhost:3000
  #   volumes:
  #     - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
  #   depends_on:
  #     coaching-writer:
  #       condition: service_healthy
  #     open-webui:
  #       condition: service_healthy
  #   networks:
  #     - cosmic_net

  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    container_name: cw_pipelines
    environment:
      - OPENSI_COSMIC_API_BASE_URL=http://coaching-writer:8001
      # - MAX_QUERIES_PER_USER=10
      - PIPELINES_URLS=file:///ext_pipelines/coaching_writer_pipeline.py
    volumes:
      - ./pipelines:/ext_pipelines:ro
    depends_on:
      coaching-writer:
        condition: service_started
    ports:
      - "9099:9099"
    restart: unless-stopped
    networks:
      - cosmic_net

volumes:
  ollama: {}
  vector_db: {}
  volume_configs: {}
  open-webui: {}
  shared_mount:
    external: true

networks:
  cosmic_net:
    driver: bridge
