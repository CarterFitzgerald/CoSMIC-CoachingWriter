"""
coaching_writer_pipeline.py
---------------------------

Defines the **OpenWebUI pipeline** for the CoSMIC Coaching Writer system.

A pipeline in OpenWebUI acts as a middleware layer between:
  • The front-end chat interface (user messages, uploaded files)
  • The backend API service (`/coach/query`), which performs retrieval-augmented generation (RAG)
    and returns structured coaching feedback.

Core responsibilities:
  - Detect conversational vs. academic coaching queries.
  - Enforce strict safety rules (never rewrite or produce user text).
  - Forward the request payload to the FastAPI coaching service.
  - Enforce per-user query limits to prevent API abuse.

Environment variables:
  - `OPENSI_COSMIC_API_BASE_URL`: Base URL of the Coaching Writer backend (default http://coaching-writer:8001)
  - `MAX_QUERIES_PER_USER`: Query cap per user session (default 1000)

All responses are generated by the backend; this pipeline contains no model inference.
"""

import os
import requests
from typing import List

# --------------------------------------------------------------------------
# Mode Detection
# --------------------------------------------------------------------------

def detect_mode(text: str) -> str:
    """
    Heuristically classify an incoming user message as either conversational
    or academic/task-oriented.

    Args:
        text (str): The raw user message.

    Returns:
        str: One of {"chat", "task", None}.
    """
    chat_keywords = ["hi", "hello"]
    task_keywords = [
        "assignment", "essay", "draft", "section", "paper",
        "review", "improve", "help", "suggest", "feedback"
    ]

    lower = text.lower()
    if any(kw in lower for kw in task_keywords):
        return "task"
    if any(kw in lower for kw in chat_keywords):
        return "chat"
    return None


# --------------------------------------------------------------------------
# Safety Instructions
# --------------------------------------------------------------------------

SAFETY_INSTRUCTION = (
    "IMPORTANT: Never rewrite or generate new text for the user. "
    "Only provide constructive feedback, suggestions, and advice "
    "on how the user can improve their own writing."
)


# --------------------------------------------------------------------------
# Pipeline Definition
# --------------------------------------------------------------------------

class Pipeline:
    """
    OpenWebUI pipeline for the CoSMIC Coaching Writer.

    This pipeline is automatically registered with OpenWebUI’s
    `pipelines` service and invoked for each chat message.

    Attributes:
        id (str): Pipeline identifier (used by OpenWebUI).
        name (str): Display name for the pipeline.
        base (str): Backend service URL.
        max_q (int): Max queries allowed per non-admin user.
        user_queries (dict): Per-user query counter.
    """

    def __init__(self):
        self.id = "coaching_writer_pipeline"
        self.name = "CoSMIC Coaching Writer"
        self.base = os.getenv("OPENSI_COSMIC_API_BASE_URL", "http://coaching-writer:8001")
        self.max_q = int(os.getenv("MAX_QUERIES_PER_USER", "1000"))
        self.user_queries = {}

    async def on_startup(self):
        """Lifecycle hook triggered when the pipeline initializes."""
        print("[Pipeline] Coaching Writer ready")

    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict):
        """
        Process a user query and forward it to the Coaching Writer backend.

        Args:
            user_message: Raw text entered by the user.
            model_id: The model selected in the OpenWebUI frontend.
            messages: Chat history (unused here).
            body: Additional context (e.g., user info, attached files).

        Returns:
            str: Backend-generated feedback message.
        """
        # Ignore internal/system messages
        if user_message.startswith("###"):
            return ""

        uid = body.get("user", {}).get("id", "anon")
        role = body.get("user", {}).get("role", "user")
        documents = body.get("files") or body.get("documents") or []

        # Enforce per-user query limit
        count = self.user_queries.get(uid, 0)
        if role != "admin" and count >= self.max_q:
            return "Query limit reached."
        self.user_queries[uid] = count + 1

        use_rag = True
        mode = None
        text = user_message.strip()

        # Command shortcuts (developers/admin use)
        if text.lower().startswith('/norag '):
            use_rag = False
            text = text[7:].strip()

        if text.lower().startswith('/mode:'):
            parts = text.split(' ', 1)
            if len(parts) == 2:
                mode = parts[0].split(':', 1)[1]
                text = parts[1]

        # Auto-detect conversation/task mode
        if not mode:
            mode = detect_mode(text)

        # Add global safety instruction
        query_with_safety = f"{text}\n\n{SAFETY_INSTRUCTION}"

        if mode == "task":
            query_with_safety += (
                "\n\nREMINDER: Do not provide rewritten or rephrased sentences. "
                "Focus on writing principles and conceptual feedback."
            )

        payload = {
            "query": query_with_safety,
            "use_rag": use_rag,
            "mode": mode,
            "documents": documents
        }

        try:
            r = requests.post(f"{self.base}/coach/query", json=payload, timeout=1000)
            if r.status_code != 200:
                return f"[Error {r.status_code}] {r.text}"
            data = r.json()
            return data.get('response', '')
        except Exception as e:

            return f"[Pipeline Exception] {e}"
